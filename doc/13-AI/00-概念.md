# 概念

## 1.什么是大模型 Agent?它与传统的 AI系统有什么不同?

大模型 Agent(LLM Agent)是一种基于大型语言模型(LLM)的智能体，能够自主解析任务、调用工具、执行推理，并与环境交互。它通常具备以下特点：

- 基于 LLM 的决策:利用大模型的自回归生成能力进行推理，而非传统的手工编写规则或强化学习策略。
- 动态工具调用:可以根据任务需要调用 API.数据库、搜索引擎或外部计算工具(如Wolfram Alpha)
- 上下文记忆:通过长上下文窗口或外部存储(如 RAG、向量数据库)维护长期记忆，以支持跨回合交互。
- 可扩展性:与传统 AI系统相比，LLM Agent可以无缝适配不同任务，而无需针对特定任务进行定制。

## Q2.LLM Agent 的基本架构有哪些组成部分?

LLM Agent 典型的架构包括：

1. 任务解析模块(Task Parser)通过 LLM 解析输入的任务或用户指令，识别目标和潜在子任务。
2. 计划与推理模块(Planning& Reasoning)采用基于 Chain-of-Thought(CoT)或 ReAct(Reason+Act)等技术进行多步推理，确保任务执行的合理性。
3. 工具调用(ToolUse/APICalling):通过插件机制或 API，调用搜索引擎、数据库、代码执行环境、计算引擎(如 Python 计算)。
4. 记忆管理(Memory&Retrieval):维护短期记忆(Session Context)和长期记忆(向量数据库、知识库)以支持连续对话或长期任务。

## Q3.LLM Agent 如何进行决策?能否使用具体的方法解释?

LLM Agent 的决策机制通常基于以下方法:

1. 基于 Chain-of-Thought(CoT)推理通过显式的逐步推理，使模型在生成答案前先展开推理步骤
   例如:用户:某个城市的 GDP 是否比全国平均值高?
   Agent(CoT):首先获取该城市的 GDP 数据->获取全国 GDP 平均值 ->进行比较 ->生成答案。
2. 基于 ReAct(Reasoning+Acting)框架结合逻辑推理与行动执行(如 API查询、数据库检索)，避免模型直接“胡编”答案。例如:任务:查询某个公司 2023年的财报数据 Agent(ReAct)
   思考:“我需要找到该公司的财报网站”->调用搜索引擎->获取网站链接->访问网站->提取 2023 年财报数据->生成答案。

## Q4.如何让 LLM Agent 具备长期记忆能力?

LLM 本身的上下文窗口有限，通常通过以下方式增强长期记忆

1. 向量数据库(Vector Database)+ RAG(Retrieval-Augmented Generation)关键步骤:
   将历史对话或知识存入向量数据库(如FAISS、ChromaDB)在交互时检索相关内容，合并进LLM 的输入上
   下文。
2. Memory Transformer / Hierarchical Memory通过分层存储记忆:
   - 短期记忆(SessionContext):保留最近的对话内容。
   - 长期记忆(Long-Term Embeddings):重要信息存入外部存储，并在必要时召回。
