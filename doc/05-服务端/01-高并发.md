# 高并发

高并发（High Concurrency）本质上描述的是：

> 在同一时间段内，有大量请求同时访问同一个系统或资源，系统仍然能够稳定、快速地响应。

## 一、一句话理解

高并发不是“访问量大”，而是“同时来的请求多”。

举个直观例子：

- ❌ 一天 1 亿次访问，但均匀分布（不算高并发）
- ✅ 1 秒钟 10 万个请求同时打进来（典型高并发）

## 二、几个容易混淆的概念

| 概念  | 含义             | 关注点         |
| --- | -------------- | ----------- |
| 并发  | 同一时间段内同时处理多个请求 | **数量**      |
| 高并发 | 并发数量非常大        | **系统承载能力**  |
| 吞吐量 | 单位时间处理请求总数     | **TPS/QPS** |
| 高可用 | 出问题还能用         | **稳定性**     |
| 高性能 | 单请求响应快         | **延迟**      |

📌 高并发 ≠ 高性能 ≠ 高吞吐，但高度相关

## 三、如何量化“高并发”

常见指标

| 指标    | 说明              |
| ----- | --------------- |
| QPS   | 每秒请求数           |
| TPS   | 每秒事务数           |
| 并发用户数 | 同时在线 / 同时请求的用户数 |
| RT    | 响应时间（P99 很关键）   |
| 错误率   | 请求失败比例          |

经验值（非绝对）

| 场景     | 并发量    |
| ------ | ------ |
| 普通后台系统 | 几百～几千  |
| 电商活动页  | 几万～几十万 |
| 秒杀系统   | 十万～百万级 |

## 四、高并发问题本质是什么？

> 👉 有限资源 × 大量同时请求

常见瓶颈

| 层级  | 瓶颈       |
| --- | -------- |
| 网络  | 带宽、连接数   |
| 应用  | 线程数、事件循环 |
| 数据库 | 连接池、锁    |
| 缓存  | 热点 key   |
| 单机  | CPU / 内存 |

## 五、高并发下会出现什么问题

- ❌ 接口超时
- ❌ 数据库被打爆
- ❌ CPU 飙高
- ❌ 锁竞争严重
- ❌ 服务雪崩

## 六、应对高并发的核心思路

> 削峰 + 分流 + 扩容 + 提效 + 保护

- 削峰（最重要）
  - 缓存（本地 / Redis）
  - 静态化（CDN、预渲染）
  - 异步（MQ）
- 分流
  - 负载均衡（Nginx / SLB）
- 扩容
  - 水平扩展（多实例）
- 提效
  - 减少 IO
  - 批量处理
  - 无锁 / 少锁设计
- 保护
  - 限流。固定窗口、滑动窗口、令牌桶。限制 IP、用户、接口
  - 熔断
  - 降级

## 七、前端视角下的高并发

从前端工程师角度：

前端不是“没关系”，反而是第一道防线

- 请求合并
- 防抖 / 节流
- 本地缓存
- CDN
- 懒加载
- 避免轮询风暴

👉 很多高并发问题，其实是前端“无脑请求”放大的

## 九、总结

高并发是指在同一时间内，有大量请求同时访问系统。
它关注的是系统在高并发请求下的处理能力和稳定性，而不仅仅是访问总量。
高并发系统通常需要通过缓存、限流、异步、负载均衡等手段，来解决资源竞争和性能瓶颈问题。
